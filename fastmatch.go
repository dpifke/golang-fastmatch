// Copyright (c) 2014-2016 Dave Pifke.
//
// Redistribution and use in source and binary forms, with or without
// modification, is permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
//    this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright notice,
//    this list of conditions and the following disclaimer in the documentation
//    and/or other materials provided with the distribution.
//
// 3. Neither the name of the copyright holder nor the names of its
//    contributors may be used to endorse or promote products derived from
//    this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

/*
Package fastmatch provides a code generation tool for quickly comparing an
input string to a set of possible matches which are known at compile time.

A typical use of this would be a "reverse enum", such as in a parser which
needs to compare a string to a list of keywords and return the corresponding
lexer symbol.

Normally, the easiest way to do this would be with a switch statement, such
as:

	switch (input) {
	case "foo":
		return foo
	case "bar":
		return bar
	case "baz":
		return baz
	}

The compiled code for the above will compare the input to each string in
sequence.  If input doesn't match "foo", we try to match "bar", then "baz".
The matching process starts anew for each case.  If we have lots of possible
matches, this can be a lot of wasted effort.

Another option would be to use a map, on the (probably valid) assumption that
Go's map lookups are faster than executing a bunch of string comparisons in
sequence:

	match := map[string]int{
		"foo": foo,
		"bar": bar,
		"baz": baz,
	}
	return match[input]

The compiled code for the above will recreate the map at runtime.  We thus
have to hash each possible match every time the map is initialized, allocate
memory, garbage collect it, etc.  More wasted effort.

And this is all not to mention the potential complications related to
case-insensitive matching, partial matches (e.g. strings.HasPrefix and
strings.HasSuffix), Unicode normalization, or situations where we want to
treat a class of characters (such as all numeric digits) as equivalent for
matching purposes.  You could use a regular expression, but now you'd have two
problems, as the jwz quote goes.

The code generated by this package is theoretically more efficient than the
preceding approaches.  It supports partial matches, and can treat groups of
characters (e.g. 'a' and 'A') as equivalent.

Under the hood, it works by partitioning the search space by the length of the
input string, then updating a state machine based on each rune in the input.
If the character at a given position in the input doesn't correspond to any
possible match, we bail early.  Otherwise, the final state is compared against
possible matches using a final switch statement.

Is the code output by this package faster enough to matter?  Maybe, maybe not.
This is a straight port of a C code generation tool I've used on a couple of
projects.  In C, the difference was significant, due to strcmp() or
strcasecmp() function call overhead, and GCC's ability to convert long switch
statements into jump tables or binary searches.

Go (as of 1.7) doesn't yet do any optimization of switch statements.  See
https://github.com/golang/go/issues/5496 and
https://github.com/golang/go/issues/15780.  Thus, you may actually be worse
off in the short-term for using this method instead of a map lookup.
(Certainly in terms of code size.)  But as the compiler improves, this code
will become more relevant.  I've played with having this package output
assembler code, but it seems like the effort would be better spent improving
the compiler instead.

This probably isn't the right tool to use if your possible matches are longer
than short words or phrases, or if you have a ridiculous number of them, since
the state machine counter has to fit within a uint64.  It will return an error
at code generation time if this limit is exceeded.  One could possibly work
around this limitation by splitting up the search space using HasPrefix or
HasSuffix.
*/
package fastmatch

import (
	"bytes"
	"errors"
	"fmt"
	"io"
	"math"
	"sort"
	"strconv"
)

var (
	// ErrOverflow is returned when the stateMachine runs out of space for
	// storing intermediate states.  The resolution is to reduce the
	// length and/or quantity of the input strings being matched.
	ErrOverflow = errors.New("too many values to match (uint64 overflow)")

	// ErrBadFlags is returned when nonsensical flags are passed to
	// Generate.
	ErrBadFlags = errors.New("HasPrefix and HasSuffix flags are mutually exclusive")
)

// Flag can be passed to Generate and GenerateReverse to modify the functions'
// behavior.  Users of this package should not instantiate their own Flags.
// Rather, they should use one of HasPrefix, HasSuffix, Insensitive,
// Normalize, or the return value from Equivalent().  Unknown Flags are
// ignored.
type Flag struct {
	equivalent []rune
}

// Insensitive is a flag, which can be passed to Generate, to specify that
// matching should be case-insensitive.
var Insensitive = new(Flag)

// Normalize is a flag, which can be passed to Generate, to specify that
// matching should be done without regard to diacritics, accents, etc.
//
// This is currently just a placeholder, and has no effect yet on the
// generated code.
var Normalize = new(Flag)

// Equivalent is a flag, which can be passed to Generate, to specify
// runes that should be treated identically when matching.
func Equivalent(runes ...rune) *Flag {
	return &Flag{equivalent: runes}
}

// HasPrefix is a flag, which can be passed to Generate, to specify that
// runes proceeding a match should be ignored.
//
// Matching stops as soon as a match is found, thus "foo" and "f" are
// ambiguous cases when HasPrefix is specified.  Generate returns an error if
// ambiguity is detected.
var HasPrefix = new(Flag)

// HasSuffix is a flag, which can be passed to Generate, to match the end of
// the input string, in the same manner HasPrefix performs a match of the
// beginning of the string.
var HasSuffix = new(Flag)

// sortableRunes implements sort.Sortable on a slice of runes.
type sortableRunes []rune

func (r sortableRunes) Len() int           { return len(r) }
func (r sortableRunes) Swap(a, b int)      { r[a], r[b] = r[b], r[a] }
func (r sortableRunes) Less(a, b int) bool { return r[a] < r[b] }

// runeEquivalents holds our map of which runes are equivalent to each other.
type runeEquivalents map[rune]sortableRunes

// dedupedRuneEquivalents is used internally in the construction of
// runeEquivalents.
type dedupedRuneEquivalents map[rune]map[rune]bool

// set adds a rune key and zero or more values to dedupedRuneEquivalents,
// calling make() on the second-level map as needed.
func (equiv dedupedRuneEquivalents) set(r rune, rs ...rune) {
	if _, exists := equiv[r]; !exists {
		equiv[r] = make(map[rune]bool, len(rs)+1)
		equiv[r][r] = true
	}
	for _, r2 := range rs {
		equiv[r][r2] = true
	}
}

// collapse converts dedupedRuneEquivalents to runeEquivalents.
func (equiv dedupedRuneEquivalents) collapse() runeEquivalents {
	newEquiv := make(runeEquivalents, len(equiv))
	for r1, rm := range equiv {
		// If equiv['a'] contains 'b', and equiv['b'] contains 'c', we
		// want to ensure 'c' is present in equiv['a'].  This requires
		// several passes, until we've determined the transitive
		// equivalence of every rune therein.
		seen := make(map[rune]bool, len(rm))
	populateTransience:
		for {
			for r2 := range rm {
				if seen[r2] {
					continue
				}
				for r3 := range equiv[r2] {
					equiv[r1][r3] = true
				}
				seen[r2] = true
				continue populateTransience
			}
			break
		}

		// Now we can convert from map[rune]bool to sorted []rune.
		newEquiv[r1] = make(sortableRunes, 0, len(rm))
		for r2 := range rm {
			newEquiv[r1] = append(newEquiv[r1], r2)
		}
		sort.Sort(newEquiv[r1])
	}
	return newEquiv
}

// makeRuneEquivalents builds our rune equivalence map based on flags.
func makeRuneEquivalents(flags ...*Flag) runeEquivalents {
	equiv := make(dedupedRuneEquivalents)

	for _, f := range flags {
		if f == Insensitive {
			for lower := 'a'; lower <= 'z'; lower++ {
				upper := 'A' + (lower - 'a')
				equiv.set(lower, upper)
				equiv.set(upper, lower)
			}
		} else if f == Normalize {
			continue // TODO: not yet implemented
		} else if len(f.equivalent) > 0 {
			for _, r := range f.equivalent {
				equiv.set(r, f.equivalent...)
			}
		}
	}

	return equiv.collapse()
}

// lookup returns a map entry from runeEquivalents, defaulting to a slice
// containing just the lookup key if there are no equivalents for that rune.
func (equiv runeEquivalents) lookup(r rune) []rune {
	if rs, found := equiv[r]; found {
		return rs
	}
	return []rune{r}
}

// lookupString returns a string representing a map entry from
// runeEquivalents.
func (equiv runeEquivalents) lookupString(r rune) string {
	var b bytes.Buffer
	for _, r2 := range equiv.lookup(r) {
		if b.Len() != 0 {
			b.Write([]byte{',', ' '})
		}
		b.WriteString(strconv.QuoteRuneToASCII(r2))
	}
	return b.String()
}

// isEquiv returns true if two runes are equivalent.
func (equiv runeEquivalents) isEquiv(r1, r2 rune) bool {
	for _, r := range equiv.lookup(r1) {
		if r == r2 {
			return true
		}
	}
	return false
}

// uniqueAtOffset returns a sorted list (sans duplicates) of possible runes at
// a given offset for a given set of keys.
func (equiv runeEquivalents) uniqueAtOffset(keys []string, offset int) []rune {
	runes := sortableRunes(make([]rune, 0, len(keys)))
	seen := make(map[rune]bool, len(keys))
possibilities:
	for _, key := range keys {
		if len(key) > offset {
			r := rune(key[offset])
			for _, r2 := range equiv.lookup(r) {
				if seen[r2] {
					continue possibilities
				}
				seen[r2] = true
			}
			runes = append(runes, r)
		}
	}
	sort.Sort(runes)

	return runes
}

// stateMachine holds the mapping between a match and the intermediate state
// changes (runes encountered) leading up to a match.
type stateMachine struct {
	next     uint64
	base     uint64
	final    map[string][]uint64
	possible [][]rune
	changes  []map[rune]uint64
	noMore   []map[rune][]string
}

// newStateMachine initializes a stateMachine.
func newStateMachine(keys []string) *stateMachine {
	state := &stateMachine{
		next:  1,
		base:  1,
		final: make(map[string][]uint64, len(keys)),
	}
	for _, key := range keys {
		state.final[key] = make([]uint64, 0, len(key))
	}
	return state
}

// shift should be called at each new position, to ensure new intermediate
// state values do not overlap with previous ones.
func (state *stateMachine) shift() {
	state.base = state.next
}

// increment creates a new intermediate state.  It returns an error if we have
// too many intermediate states to fit in a uint64.
func (state *stateMachine) increment() error {
	if state.base > math.MaxUint64-state.next {
		// TODO: we can work around this by creating an additional
		// stateMachine and chaining to it.  I have a MIME type parser
		// which must deal with abominations such as
		// "application/vnd.openxmlformats-officedocument.presentationml.commentAuthors+xml",
		// so I'll probably implement this sooner rather than later.
		return ErrOverflow
	}
	state.next += state.base
	return nil
}

// indexKeys assigns a unique state value to each possible state change.  For
// partial matching, this method also notes where the state should be checked
// against possible final values.
func (state *stateMachine) indexKeys(equiv runeEquivalents, partialMatch bool) error {
	longestKey := 0
	keys := make([]string, 0, len(state.final))
	for key := range state.final {
		keys = append(keys, key)
		if len(key) > longestKey {
			longestKey = len(key)
		}
	}

	needShift := true
	state.possible = make([][]rune, longestKey)
	state.changes = make([]map[rune]uint64, longestKey)
	state.noMore = make([]map[rune][]string, longestKey)
	for offset := 0; offset < longestKey; offset++ {
		state.possible[offset] = equiv.uniqueAtOffset(keys, offset)

		if len(state.possible[offset]) > 1 {
			if needShift {
				state.shift()
				needShift = false
			}

			state.changes[offset] = make(map[rune]uint64, len(keys))
			for _, r := range state.possible[offset] {
				needIncr := false
				for _, key := range keys {
					if partialMatch && offset >= len(key)-1 {
						continue
					}
					if equiv.isEquiv(rune(key[offset]), r) {
						state.final[key] = append(state.final[key], state.next)
						needIncr = true
					}
				}
				if needIncr {
					state.changes[offset][r] = state.next
					if err := state.increment(); err != nil {
						return err
					}
					needShift = true
				}
			}
		}

		state.noMore[offset] = make(map[rune][]string, len(state.possible[offset]))
		if partialMatch {
			for _, r := range state.possible[offset] {
				for _, key := range keys {
					if len(key)-1 == offset && equiv.isEquiv(rune(key[offset]), r) {
						state.noMore[offset][r] = append(state.noMore[offset][r], key)
					}
				}
			}
		}
	}

	return nil
}

// deleteKey forgets about a possible match.  This is called by checkAmbiguity
// to prune redundant keys, so that we don't output duplicate or unreachable
// case statements.
func (state *stateMachine) deleteKey(key string) {
	delete(state.final, key)

	for _, noMore := range state.noMore {
		for r := range noMore {
			for n := range noMore[r] {
				if noMore[r][n] == key {
					if n < len(noMore[r])-1 {
						copy(noMore[r][n:], noMore[r][n+1:])
					}
					noMore[r] = noMore[r][:len(noMore[r])-1]
					if n >= len(noMore[r])-1 {
						break
					}
				}
			}
		}
	}
}

// checkAmbiguity verifies there is exactly one possible return value for each
// final state, returning an error if any matches are ambiguous.
func (state *stateMachine) checkAmbiguity(cases map[string]string, backwards bool) error {
	// map[final state] -> map[final rune] -> map[return value] -> map[key] -> true
	ambiguity := make(map[uint64]map[rune]map[string]map[string]bool, len(cases))
	for key, values := range state.final {
		var sum uint64
		for _, value := range values {
			sum += value
		}

		// Look in state.noMore for this key; the final rune may be
		// distinct, but doesn't have a state value assigned to it.
		var nm rune
		for r, keys := range state.noMore[len(key)-1] {
			for _, k := range keys {
				if k == key {
					nm = r
					break
				}
			}
		}

		if _, exists := ambiguity[sum]; !exists {
			ambiguity[sum] = make(map[rune]map[string]map[string]bool)
		}
		if _, exists := ambiguity[sum][nm]; !exists {
			ambiguity[sum][nm] = make(map[string]map[string]bool)
		}
		if _, exists := ambiguity[sum][nm][cases[key]]; !exists {
			ambiguity[sum][nm][cases[key]] = make(map[string]bool)
		}
		ambiguity[sum][nm][cases[key]][key] = true

		if nm != 0 {
			// Add longer keys which share the same final rune and
			// intermediate state.
			for other, values := range state.final {
				if len(other) <= len(key) {
					continue // not longer
				}

				var otherSum uint64
				if len(values) >= len(key) {
					if values[len(key)-1] != state.changes[len(key)-1][nm] {
						continue // different final rune
					}

					for n := 0; n < len(key)-1; n++ {
						otherSum += values[n]
					}
				} else {
					for _, value := range values {
						otherSum += value
					}
				}

				if otherSum != sum {
					continue // different intermediate state
				}

				if _, exists := ambiguity[sum][nm][cases[other]]; !exists {
					ambiguity[sum][nm][cases[other]] = make(map[string]bool)
				}
				ambiguity[sum][nm][cases[other]][other] = true
			}
		}
	}

	var b bytes.Buffer
	for _, finalChars := range ambiguity {
		for _, returnValues := range finalChars {
			if len(returnValues) == 1 {
				// Not ambiguous, but delete all but the
				// shortest key that maps to this return
				// value.  This eliminates duplicate and
				// unreachable case statements.
				var returnValue string
				for returnValue = range returnValues {
				}
				var shortest string
				for key := range returnValues[returnValue] {
					if shortest == "" || len(key) < len(shortest) {
						shortest = key
					}
				}
				for key := range returnValues[returnValue] {
					if key != shortest {
						state.deleteKey(key)
					}
				}

				continue
			}

			if b.Len() == 0 {
				b.WriteString("ambiguous matches: ")
			} else {
				b.Write([]byte{';', ' '})
			}
			first := true
			for _, keys := range returnValues {
				for key := range keys {
					if backwards {
						key = reverseString(key)
					}
					if !first {
						b.Write([]byte{',', ' '})
					} else {
						first = false
					}
					b.WriteString(strconv.Quote(key))
				}
			}
		}
	}

	if b.Len() == 0 {
		return nil
	}
	return errors.New(b.String())
}

// finalString returns a string representing the final state of each key.  To
// make the generated code slightly more readable, this consists of an
// expression summing each intermediate state value (in hex).
func (state *stateMachine) finalString(key string) string {
	if len(state.final[key]) == 0 {
		return "0"
	}

	var b bytes.Buffer
	for n, value := range state.final[key] {
		if n != 0 {
			b.WriteString(" + ")
		}
		b.WriteString(fmt.Sprintf("0x%x", value))
	}
	return b.String()
}

// reverseString returns a string in reverse order.  I'm shocked this isn't
// part of the standard library.
func reverseString(s string) string {
	r := []rune(s)
	for i, j := 0, len(r)-1; i < j; i, j = i+1, j-1 {
		r[i], r[j] = r[j], r[i]
	}
	return string(r)
}

// Generate outputs Go code to compare a string to a set of possible matches
// which are known at compile-time.
//
// Each entry in the map consists of a possible match as the key, and the
// corresponding expression to return as the value.  none is the expression to
// return if no match is found.
//
// Code to perform the match is written to the supplied io.Writer.  Before
// calling this function, the caller is expected to write the method signature
// and any input pre-processing logic.  The string to examine should be in a
// variable named "input".
//
// If flags are specified, it's possible to generate ambiguous code, in which
// the same input string will match multiple entries in the cases map, with
// different return values.  This function attempts to detect this and will
// return an error if ambiguity is detected.
//
// An error is also returned if the provided io.Writer is invalid, or if there
// are too many matches to fit within our uint64 state machine.
//
// The output is not buffered, and will be incomplete if an error is
// returned.  If the caller cares about this, they should have a way to
// discard the written output on error.
//
// Example usage:
//
//	fmt.Fprintln(w, "func matchFoo(input string) int {")
//	fastmatch.Generate(w, map[string]string{
//		"foo": "1",
//		"bar": "2",
//		"baz": "3",
//	}, "-1", fastmatch.Insensitive)
func Generate(w io.Writer, origCases map[string]string, none string, flags ...*Flag) error {
	equiv := makeRuneEquivalents(flags...)
	partialMatch := false
	backwards := false
	for _, flag := range flags {
		if flag == HasPrefix {
			if backwards {
				return ErrBadFlags
			}
			partialMatch = true
		} else if flag == HasSuffix {
			if partialMatch && !backwards {
				return ErrBadFlags
			}
			partialMatch = true
			backwards = true
		}
	}

	// For backwards matching (HasSuffix), reverse the order of the
	// strings being searched for:
	var cases map[string]string
	if backwards {
		cases = make(map[string]string, len(origCases))
		for key, value := range origCases {
			cases[reverseString(key)] = value
		}
	} else {
		cases = origCases
	}

	// Search is partitioned based on the length of the input.  Split
	// cases into each possible search space:
	keys := make(map[int][]string)
	for key := range cases {
		keys[len(key)] = append(keys[len(key)], key)
	}
	lengths := sort.IntSlice(make([]int, 0, len(keys)))
	for len := range keys {
		lengths = append(lengths, len)
	}
	sort.Sort(sort.Reverse(lengths))

	// For partial matching, include shorter cases in the search space for
	// longer ones.  (Reminder: lengths array is sorted in descending
	// order.)
	if partialMatch {
		for i := len(lengths) - 1; i > 0; i-- {
			smaller := lengths[i]
			bigger := lengths[i-1]
			keys[bigger] = append(keys[bigger], keys[smaller]...)
		}
	}

	wroteSwitch := false
	for _, l := range lengths {
		state := newStateMachine(keys[l])
		if err := state.indexKeys(equiv, partialMatch); err != nil {
			return err
		}
		if err := state.checkAmbiguity(cases, backwards); err != nil {
			return err
		}

		// We don't bother checking the fmt.Fprint return value
		// everywhere, but we do want to do so once early on, so we
		// can bail if our effort is going to waste.  We also check it
		// on the final write, to make sure our io.Writer is still
		// good.
		if partialMatch {
			if _, err := fmt.Fprintf(w, "\tif len(input) >= %d {", l); err != nil {
				return err
			}
		} else {
			if !wroteSwitch {
				fmt.Fprintln(w, "\tswitch len(input) {")
				wroteSwitch = true
			}
			if _, err := fmt.Fprintf(w, "\tcase %d:", l); err != nil {
				return err
			}
		}
		fmt.Fprintln(w)
		fmt.Fprintln(w, "\t\tvar state uint64")

		for offset := 0; offset < l; offset++ {
			if backwards {
				fmt.Fprintf(w, "\t\tswitch input[len(input)-%d] {", offset+1)
			} else {
				fmt.Fprintf(w, "\t\tswitch input[%d] {", offset)
			}
			fmt.Fprintln(w)
			for _, r := range state.possible[offset] {
				fmt.Fprintf(w, "\t\tcase %s:", equiv.lookupString(r))
				fmt.Fprintln(w)

				if len(state.noMore[offset][r]) == 1 {
					fmt.Fprintln(w, "\t\t\treturn", cases[state.noMore[offset][r][0]])
				} else if len(state.noMore[offset][r]) > 0 {
					fmt.Fprintln(w, "\t\t\tswitch state {")
					for _, key := range state.noMore[offset][r] {
						fmt.Fprintf(w, "\t\t\tcase %s:", state.finalString(key))
						fmt.Fprintln(w)
						fmt.Fprintln(w, "\t\t\t\treturn", cases[key])
					}
					fmt.Fprintln(w, "\t\t\t}")
				}

				if state.changes[offset][r] > 0 {
					fmt.Fprintf(w, "\t\t\tstate += 0x%x", state.changes[offset][r])
					fmt.Fprintln(w)
				}
			}
			if !partialMatch || offset != l-1 {
				fmt.Fprintln(w, "\t\tdefault:")
				fmt.Fprintln(w, "\t\t\treturn", none)
			}
			fmt.Fprintln(w, "\t\t}") // end of "switch input[offset]"
		}

		if state.next == 1 {
			// Prevent compiler from complaining:
			fmt.Fprintln(w, "\t\t_ = state")
		}

		if partialMatch {
			// Final switch block has already been emitted.
			fmt.Fprintln(w, "\t\treturn", none)
			fmt.Fprintln(w, "\t}") // end of "if len(input)"
		} else {
			// Compare actual state to possible final values:
			if len(state.final) == 1 && state.next == 1 {
				for key := range state.final {
					fmt.Fprintln(w, "\t\treturn", cases[key])
				}
			} else {
				fmt.Fprintln(w, "\t\tswitch state {")
				for key := range state.final {
					fmt.Fprintf(w, "\t\tcase %s:", state.finalString(key))
					fmt.Fprintln(w)
					fmt.Fprintln(w, "\t\t\treturn", cases[key])
				}
				fmt.Fprintln(w, "\t\t}")
			}
		}
	}
	if wroteSwitch {
		fmt.Fprintln(w, "\t}") // end of "switch len(input)"
	}
	fmt.Fprintln(w, "\treturn", none)
	_, err := fmt.Fprintln(w, "}") // end of func
	return err
}

// GenerateReverse outputs Go code that returns the string value for a given
// match.  The result from the generated function will be the reverse of that
// from a function generated with Generate.
//
// If the supplied io.Writer is not valid, or if more than one string maps to
// the same value, an error is returned.
//
// This function accepts flags (in order to match Generate's function
// signature), but they are currently ignored.
func GenerateReverse(w io.Writer, cases map[string]string, none string, _ ...*Flag) error {
	keys := make([]string, 0, len(cases))
	for key := range cases {
		keys = append(keys, key)
	}
	sort.Strings(keys)

	if _, err := fmt.Fprintln(w, "\tswitch input {"); err != nil {
		return err
	}
	ambiguity := make(map[string][]string, len(cases))
	for _, key := range keys {
		ambiguity[cases[key]] = append(ambiguity[cases[key]], key)
		fmt.Fprintf(w, "\tcase %s:", cases[key])
		fmt.Fprintln(w)
		fmt.Fprintln(w, "\t\treturn", strconv.Quote(key))
	}

	var b bytes.Buffer
	for _, returnValues := range ambiguity {
		if len(returnValues) == 1 {
			continue
		}

		if b.Len() == 0 {
			b.WriteString("ambiguous values: ")
		} else {
			b.Write([]byte{';', ' '})
		}
		first := true
		for _, value := range returnValues {
			if !first {
				b.Write([]byte{',', ' '})
			} else {
				first = false
			}
			b.WriteString(strconv.Quote(value))
		}
	}
	if b.Len() != 0 {
		return errors.New(b.String())
	}

	fmt.Fprintln(w, "\tdefault:")
	fmt.Fprintln(w, "\t\treturn", none)
	fmt.Fprintln(w, "\t}")
	fmt.Fprintln(w, "}")

	return nil
}
